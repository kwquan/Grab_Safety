{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT MODULES\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tsfresh.feature_extraction import feature_calculators\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from joblib import Parallel, delayed\n",
    "from matplotlib.pyplot import figure\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import shap\n",
    "%env JOBLIB_TEMP_FOLDER=/tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PRE-PROCESSING\n",
    "#Read the 10 training folders \n",
    "feat_1 = pd.read_csv('features_1')\n",
    "feat_2 = pd.read_csv('features_2')\n",
    "feat_3 = pd.read_csv('features_3')\n",
    "feat_4 = pd.read_csv('features_4')\n",
    "feat_5 = pd.read_csv('features_5')\n",
    "feat_6 = pd.read_csv('features_6')\n",
    "feat_7 = pd.read_csv('features_7')\n",
    "feat_8 = pd.read_csv('features_8')\n",
    "feat_9 = pd.read_csv('features_9')\n",
    "feat_10 = pd.read_csv('features_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PRE-PROCESSING\n",
    "#combine the 10 training folders into 1 dataframe \n",
    "train_X = feat_1.append(feat_2)\n",
    "train_X = train_X.append(feat_3)\n",
    "train_X = train_X.append(feat_4)\n",
    "train_X = train_X.append(feat_5)\n",
    "train_X = train_X.append(feat_6)\n",
    "train_X = train_X.append(feat_7)\n",
    "train_X = train_X.append(feat_8)\n",
    "train_X = train_X.append(feat_9)\n",
    "train_X = train_X.append(feat_10)\n",
    "train_X = train_X.reset_index(drop=True)\n",
    "train_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PRE-PROCESSING(FOR TEST SET)\n",
    "#REPLACE xxxx with file name\n",
    "#This is for reading the hold-out test file \n",
    "test_X = pd.read_csv(xxx)\n",
    "test_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PRE-PROCESSING\n",
    "#Checking rows of data\n",
    "len(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PRE-PROCESSING\n",
    "#Checking number of unique rides\n",
    "train_X.bookingID.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PRE-PROCESSING\n",
    "#Sort by unique rides, from start to end of trip\n",
    "train_X = train_X.sort_values(['bookingID','second'])\n",
    "train_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PRE-PROCESSING(FOR TEST SET)\n",
    "#Sort by unique rides, from start to end of trip \n",
    "#Note that unlike train_X, test_X index is jumbled up\n",
    "test_X = test_X.sort_values(['bookingID','second'])\n",
    "test_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PRE-PROCESSING\n",
    "#Read file containing labels for each ride \n",
    "train_y = pd.read_csv('labels')\n",
    "train_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PRE-PROCESSING\n",
    "#Merge labels with rides so that we can look at the variable distributions for each driver type later\n",
    "train_X = train_X.merge(train_y, on='bookingID', how='left')\n",
    "train_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PRE-PROCESSING\n",
    "#Separate training set into dangerous and safe drivers[0=safe,1=dangerous]\n",
    "train_X_0 = train_X[train_X['label'] == 0]\n",
    "train_X_1 = train_X[train_X['label'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PRE-PROCESSING\n",
    "#Checking first 5 rows of safe drivers set\n",
    "train_X_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PRE-PROCESSING\n",
    "#Checking first 5 rows of dangerous drivers set\n",
    "train_X_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "#Speed distribution for safe & dangerous drivers\n",
    "figure(num=None, figsize=(16, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "sns.distplot(train_X_0['Speed'],hist = False,label='Safe')\n",
    "sns.distplot(train_X_1['Speed'],hist = False,label='Dangerous')\n",
    "plt.xlabel('Speed',fontsize=9)\n",
    "locs,labels = plt.xticks()\n",
    "plt.tick_params(axis='x',which='major',labelsize=6,pad=-6)\n",
    "plt.tick_params(axis='y',which='major',labelsize=6)\n",
    "plt.show() \n",
    "#We see more outlier on the right side for dangerous drivers\n",
    "#Speed for dangerous drivers is more erratic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "#Check speed outliers for both driver types\n",
    "train_X.boxplot(by='label', column=['Speed'], grid=False)\n",
    "#As seen in the boxplot, dangerous drivers have more outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "#Check summary speed stats for safe drivers \n",
    "train_X_0['Speed'].describe()\n",
    "#Notice that negative speed values exist\n",
    "#This may be measurement errors due to GPS inaccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "#Check summary speed stats for dangerous drivers \n",
    "train_X_1['Speed'].describe()\n",
    "#Negative speed values exist for dangerous drivers as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "#Let's plot distribution of negative speed values against GPS accuracy for negative speed occurences only\n",
    "figure(num=None, figsize=(16, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "sns.distplot(train_X[train_X['Speed'] < 0]['Accuracy'],hist = False,label='Accuracy for negative speed')\n",
    "plt.xlabel('Accuracy',fontsize=9)\n",
    "locs,labels = plt.xticks()\n",
    "plt.tick_params(axis='x',which='major',labelsize=6,pad=-6)\n",
    "plt.tick_params(axis='y',which='major',labelsize=6)\n",
    "plt.show() \n",
    "#Notice the spike of high accuracy values \n",
    "#Seems that negative speed values are the result of GPS inaccuracy (denoted by the large accuracy values) \n",
    "#Need to verify for positive speed values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "#Let's plot distribution of GPS accuracy for positive speed occurences only\n",
    "train_X_pos = train_X[train_X['Speed'] > 0]\n",
    "figure(num=None, figsize=(16, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "sns.distplot(train_X_pos['Accuracy'],hist = False,label='Accuracy')\n",
    "plt.xlabel('Accuracy',fontsize=9)\n",
    "locs,labels = plt.xticks()\n",
    "plt.tick_params(axis='x',which='major',labelsize=6,pad=-6)\n",
    "plt.tick_params(axis='y',which='major',labelsize=6)\n",
    "plt.show() \n",
    "#As expected, most of them are concentrated in the region where accuracy values are low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "#Let's plot distribution of accuracy values for all speed values\n",
    "#Note that this is a combination of the above 2 plots\n",
    "figure(num=None, figsize=(16, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "sns.distplot(train_X['Accuracy'],hist = False,label='Accuracy')\n",
    "plt.xlabel('Accuracy',fontsize=9)\n",
    "locs,labels = plt.xticks()\n",
    "plt.tick_params(axis='x',which='major',labelsize=6,pad=-6)\n",
    "plt.tick_params(axis='y',which='major',labelsize=6)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "#Check summary accuracy stats for all drivers \n",
    "train_X['Accuracy'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "#Plot gyro_z distribution for safe & dangerous drivers\n",
    "figure(num=None, figsize=(16, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.subplot(2,1,2)\n",
    "sns.distplot(train_X_0['gyro_z'],hist = False,label='gyro_z for safe drivers')\n",
    "sns.distplot(train_X_1['gyro_z'],hist = False,label='gyro_z for dangerous drivers')\n",
    "plt.xlabel('gyro_z',fontsize=9)\n",
    "locs,labels = plt.xticks()\n",
    "plt.tick_params(axis='x',which='major',labelsize=6,pad=-6)\n",
    "plt.tick_params(axis='y',which='major',labelsize=6)\n",
    "plt.show() \n",
    "#distribution seems to be the same for both driver types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "#Check summary gyro_z stats for safe drivers \n",
    "train_X_0['gyro_z'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "#Check summary accuracy stats for dangerous drivers \n",
    "train_X_1['gyro_z'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "#Plot gyro_y distribution for safe & dangerous drivers\n",
    "figure(num=None, figsize=(16, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.subplot(2,1,2)\n",
    "sns.distplot(train_X_0['gyro_y'],hist = False,label='gyro_y for safe drivers')\n",
    "sns.distplot(train_X_1['gyro_y'],hist = False,label='gyro_y for dangerous drivers')\n",
    "plt.xlabel('gyro_y',fontsize=9)\n",
    "locs,labels = plt.xticks()\n",
    "plt.tick_params(axis='x',which='major',labelsize=6,pad=-6)\n",
    "plt.tick_params(axis='y',which='major',labelsize=6)\n",
    "plt.show() \n",
    "#distribution seems to be the same for both driver types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "#Check summary gyro_y stats for safe drivers \n",
    "train_X_0['gyro_y'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "#Check summary gyro_y stats for dangerous drivers \n",
    "train_X_1['gyro_y'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "#Plot gyro_x distribution for safe & dangerous drivers\n",
    "figure(num=None, figsize=(16, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.subplot(2,1,2)\n",
    "sns.distplot(train_X_0['gyro_x'],hist = False,label='gyro_x for safe drivers')\n",
    "sns.distplot(train_X_1['gyro_x'],hist = False,label='gyro_x for dangerous drivers')\n",
    "plt.xlabel('gyro_x',fontsize=9)\n",
    "locs,labels = plt.xticks()\n",
    "plt.tick_params(axis='x',which='major',labelsize=6,pad=-6)\n",
    "plt.tick_params(axis='y',which='major',labelsize=6)\n",
    "plt.show() \n",
    "#distribution seems to be the same for both driver types\n",
    "#however, values for safe drivers seem to be slightly-higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "#Check summary gyro_x stats for safe drivers \n",
    "train_X_0['gyro_x'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "#Check summary gyro_x stats for dangerous drivers \n",
    "train_X_1['gyro_x'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "#Plot acc_z distribution for safe & dangerous drivers\n",
    "figure(num=None, figsize=(16, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.subplot(2,1,2)\n",
    "sns.distplot(train_X_0['acceleration_z'],hist = False,label='acc_z for safe drivers')\n",
    "sns.distplot(train_X_1['acceleration_z'],hist = False,label='acc_z for dangerous drivers')\n",
    "plt.xlabel('acc_z',fontsize=9)\n",
    "locs,labels = plt.xticks()\n",
    "plt.tick_params(axis='x',which='major',labelsize=6,pad=-6)\n",
    "plt.tick_params(axis='y',which='major',labelsize=6)\n",
    "plt.show() \n",
    "#distribution seems to be the same for both driver types\n",
    "#however, values for safe drivers seem to be slightly-higher\n",
    "#dangerous drivers seem to have slightly-lower peak but fatter tails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "#Check summary acceleration_z stats for safe drivers \n",
    "train_X_0['acceleration_z'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "#Check summary acceleration_z stats for dangerous drivers \n",
    "train_X_1['acceleration_z'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "#Plot acc_y distribution for safe & dangerous drivers\n",
    "figure(num=None, figsize=(16, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.subplot(2,1,2)\n",
    "sns.distplot(train_X_0['acceleration_y'],hist = False,label='acc_y for safe drivers')\n",
    "sns.distplot(train_X_1['acceleration_y'],hist = False,label='acc_y for dangerous drivers')\n",
    "plt.xlabel('acc_y',fontsize=9)\n",
    "locs,labels = plt.xticks()\n",
    "plt.tick_params(axis='x',which='major',labelsize=6,pad=-6)\n",
    "plt.tick_params(axis='y',which='major',labelsize=6)\n",
    "plt.show() \n",
    "#distribution seems to be the same for both driver types\n",
    "#interesting 2 peaks observed\n",
    "#however, values for safe drivers seem to be slightly-higher\n",
    "#dangerous drivers seem to have slightly-lower peaks, and have values shifted slightly to the right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "#Check summary acceleration_y stats for safe drivers \n",
    "train_X_0['acceleration_y'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "#Check summary acceleration_y stats for dangerous drivers \n",
    "train_X_1['acceleration_y'].describe()\n",
    "#dangerous drivers have higher max,lower min\n",
    "#implies abrupt acc & jam-brakes may be large contributor to driver differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "#Plot acc_x distribution for safe & dangerous drivers\n",
    "figure(num=None, figsize=(16, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.subplot(2,1,2)\n",
    "sns.distplot(train_X_0['acceleration_x'],hist = False,label='acc_x for safe drivers')\n",
    "sns.distplot(train_X_1['acceleration_x'],hist = False,label='acc_x for dangerous drivers')\n",
    "plt.xlabel('acc_x',fontsize=9)\n",
    "locs,labels = plt.xticks()\n",
    "plt.tick_params(axis='x',which='major',labelsize=6,pad=-6)\n",
    "plt.tick_params(axis='y',which='major',labelsize=6)\n",
    "plt.show() \n",
    "#distribution seems to be the same for both driver types\n",
    "#however, values for safe drivers seem to be slightly-higher\n",
    "#dangerous drivers seem to have slightly-lower peak but fatter tails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "#Check summary acceleration_x stats for safe drivers \n",
    "train_X_0['acceleration_x'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "#Check summary acceleration_x stats for dangerous drivers \n",
    "train_X_1['acceleration_x'].describe()\n",
    "#dangerous drivers have higher acc_x std\n",
    "#much bigger max \n",
    "#much lower min\n",
    "#implying abrupt acc & dcc during turns may be large contributor to driver type differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "#Plot bearing distribution for safe & dangerous drivers\n",
    "figure(num=None, figsize=(16, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.subplot(2,1,2)\n",
    "sns.distplot(train_X_0['Bearing'],hist = False,label='bearing for safe drivers')\n",
    "sns.distplot(train_X_1['Bearing'],hist = False,label='bearing for dangerous drivers')\n",
    "plt.xlabel('bearing',fontsize=9)\n",
    "locs,labels = plt.xticks()\n",
    "plt.tick_params(axis='x',which='major',labelsize=6,pad=-6)\n",
    "plt.tick_params(axis='y',which='major',labelsize=6)\n",
    "plt.show() \n",
    "#distribution is the same for both driver types\n",
    "#result is expected since we don't expect dangerous drivers to prefer certain routes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "#Correlation matrix for safe drivers\n",
    "corr = train_X_0.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY DATA ANALYSIS\n",
    "#Correlation matrix for dangerous drivers\n",
    "corr = train_X_1.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PROCESSING\n",
    "#There exist some bookings with both labels\n",
    "#Find such bookings & add to to_drop\n",
    "#we are going to drop these bookings from our training set \n",
    "to_drop = []\n",
    "for i in train_X.bookingID.unique():\n",
    "    if len(train_y[train_y['bookingID'] == i]) > 1:\n",
    "        to_drop.append(i)\n",
    "#check number of bookings with dubious labels        \n",
    "len(to_drop)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PROCESSING\n",
    "#Drop rides with dubious labels from both train_X & train_y\n",
    "train_y = train_y[~train_y['bookingID'].isin(to_drop)]\n",
    "train_X = train_X[~train_X['bookingID'].isin(to_drop)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PROCESSING\n",
    "#Check for trips with only negative speeds & add to to_drop\n",
    "to_drop = []\n",
    "for i in tqdm(train_X.bookingID.unique()):\n",
    "    if len(train_X[(train_X.bookingID == i) & (train_X.Speed < 0)]) == len(train_X[train_X.bookingID == i]):\n",
    "        to_drop.append(i)\n",
    "#check number of bookings with dubious labels        \n",
    "len(to_drop)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PROCESSING\n",
    "#Drop rides with only negative speeds from both train_X & train_y\n",
    "train_y = train_y[~train_y['bookingID'].isin(to_drop)]\n",
    "train_X = train_X[~train_X['bookingID'].isin(to_drop)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PROCESSING\n",
    "#Check minimum accuracy for these rides with only negative speed\n",
    "#May use this value as threshold\n",
    "minimum = 100\n",
    "for i in to_drop:\n",
    "    if train_X[train_X.bookingID == i]['Accuracy'].min() < minimum:\n",
    "        minimum = train_X[train_X.bookingID == i]['Accuracy'].min()\n",
    "minimum        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PROCESSING(FOR TEST SET)\n",
    "#Check for trips with only negative speeds & add to to_drop \n",
    "to_drop = []\n",
    "for i in tqdm(test_X.bookingID.unique()):\n",
    "    if len(test_X[(test_X.bookingID == i) & (test_X.Speed < 0)]) == len(test_X[test_X.bookingID == i]):\n",
    "        to_drop.append(i)\n",
    "#check number of bookings with negative speed       \n",
    "len(to_drop) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PROCESSING(FOR TEST SET)\n",
    "#Drop rides with only negative speeds from test_X\n",
    "test_X = test_X[~test_X['bookingID'].isin(to_drop)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PROCESSING(FOR TEST SET)\n",
    "#Reset index for test_X, for applying smooth_feature & negative functions later\n",
    "#Note that train_X index has already been reset via merge function\n",
    "test_X.reset_index(drop=True,inplace=True)\n",
    "test_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PROCESSING\n",
    "#This is a function used to fix inaccurate values due to GPS inaccuracy\n",
    "#1) For each ride, get dataframe for that ride(df) & dataframe for that ride with rows accuracy > 10(df_filtered)\n",
    "#2) Pass indices of both dataframes to 2 lists(idx & idx_filtered)\n",
    "#3) For each index in idx_filtered(inaccurate values), search for nearest 2 indices that are in idx(accurate values), subjected to idx range\n",
    "#4) Using the index in idx_filtered ,range between nearest 2 indices in idx & range between idx_filtered index & 1st nearest idx, use formula to set new value for inaccurate value \n",
    "#5) If either of nearest 2 indices is not found, entire row containing the inaccurate value is dropped\n",
    "#6) The formula is designed such that inaccurate values will be replaced with accurate values that are gradually increasing/decreasing between nearest 2 accurate values \n",
    "def smooth_features(input_X,bookingID):\n",
    "    df = input_X[input_X.bookingID == bookingID]\n",
    "    df_filtered = input_X[(input_X.bookingID == bookingID) & (input_X.Accuracy > 10)]\n",
    "    idx_filtered = df_filtered.index.values.tolist()\n",
    "    idx = df.index.values.tolist()\n",
    "        \n",
    "    for i in idx_filtered:\n",
    "        increment_start = 1\n",
    "        increment_end = 1\n",
    "        start = i\n",
    "        end = i\n",
    "        while (idx[0] <= start-increment_start < idx[-1]) & (start-increment_start in idx_filtered):\n",
    "            increment_start += 1   \n",
    "        start -= increment_start     \n",
    "        if start >= idx[0]:\n",
    "            while (idx[0] < end+increment_end <= idx[-1]) & (end+increment_end in idx_filtered):\n",
    "                increment_end += 1\n",
    "            end += increment_end    \n",
    "            if end <= idx[-1]:\n",
    "                df.loc[i,'Speed'] = ((df['Speed'][end]-df['Speed'][start])/(end-start))*(i-start)+df['Speed'][start]  \n",
    "                df.loc[i,'acceleration_x'] = ((df['acceleration_x'][end]-df['acceleration_x'][start])/(end-start))*(i-start)+df['acceleration_x'][start] \n",
    "                df.loc[i,'acceleration_y'] = ((df['acceleration_y'][end]-df['acceleration_y'][start])/(end-start))*(i-start)+df['acceleration_y'][start] \n",
    "                df.loc[i,'acceleration_z'] = ((df['acceleration_z'][end]-df['acceleration_z'][start])/(end-start))*(i-start)+df['acceleration_z'][start] \n",
    "                df.loc[i,'gyro_x'] = ((df['gyro_x'][end]-df['gyro_x'][start])/(end-start))*(i-start)+df['gyro_x'][start] \n",
    "                df.loc[i,'gyro_y'] = ((df['gyro_y'][end]-df['gyro_y'][start])/(end-start))*(i-start)+df['gyro_y'][start] \n",
    "                df.loc[i,'gyro_z'] = ((df['gyro_z'][end]-df['gyro_z'][start])/(end-start))*(i-start)+df['gyro_z'][start]            \n",
    "            else:\n",
    "                df.drop([i],inplace=True)\n",
    "        else:\n",
    "            df.drop([i],inplace=True)\n",
    "    return df\n",
    "\n",
    "#Aply smoothing to train set\n",
    "#Create a dataframe for new training set values\n",
    "#For each ride, smooth variables & append to new dataframe\n",
    "#I used parallel processing since it takes a while to finish running\n",
    "train_X_new = pd.DataFrame(columns=['bookingID','Accuracy','Bearing','acceleration_x','acceleration_y','acceleration_z','gyro_x','gyro_y','gyro_z','second','Speed','label'],dtype=np.int64)\n",
    "features = Parallel(n_jobs=-1, verbose=2)(delayed(smooth_features)(train_X,i) for i in train_y.bookingID.unique()) \n",
    "for i, feat in tqdm(enumerate(features)):\n",
    "    train_X_new = train_X_new.append(feat)\n",
    "    \n",
    "del features\n",
    "gc.collect()\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply smoothing to test set(FOR TEST SET)\n",
    "#Create a dataframe for new test set values \n",
    "#For each ride, smooth variables & append to new dataframe\n",
    "#I used parallel processing since it takes a while to finish running\n",
    "test_X_new = pd.DataFrame(columns=['bookingID','Accuracy','Bearing','acceleration_x','acceleration_y','acceleration_z','gyro_x','gyro_y','gyro_z','second','Speed','label'],dtype=np.int64)\n",
    "features = Parallel(n_jobs=-1, verbose=2)(delayed(smooth_features)(test_X,i) for i in test_X.bookingID.unique()) \n",
    "for i, feat in tqdm(enumerate(features)):\n",
    "    test_X_new = test_X_new.append(feat)\n",
    "    \n",
    "del features\n",
    "gc.collect()\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PROCESSING\n",
    "#Check number of rides left in new training set\n",
    "train_X_new.bookingID.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PROCESSING\n",
    "#Check first 5 rows of new training set\n",
    "train_X_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PROCESSING\n",
    "#Save new training set to csv file, in case kernel is accidently-disconnected\n",
    "train_X_new.to_csv('train_X_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PROCESSING(FOR TEST SET)\n",
    "#Save new test set to csv file, in case kernel is accidently-disconnected\n",
    "test_X_new.to_csv('test_X_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PROCESSING\n",
    "#Reading new training set file\n",
    "train_X_new = pd.read_csv('train_X_new.csv')\n",
    "train_X_new.set_index('Unnamed: 0',inplace=True)\n",
    "train_X_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PROCESSING(FOR TEST SET)\n",
    "#Reading new test set file\n",
    "test_X_new = pd.read_csv('test_X_new.csv')\n",
    "test_X_new.set_index('Unnamed: 0',inplace=True)\n",
    "test_X_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PROCESSING\n",
    "#This is a function similar to the above, used to fix negative Speed values \n",
    "#I can't do both together since some negative speed values have low accuracy values\n",
    "#1) For each ride, get dataframe for that ride(df) & dataframe for that ride with rows speed < 0(df_filtered)\n",
    "#2) Pass indices of both dataframes to 2 lists(idx & idx_filtered)\n",
    "#3) For each index in idx_filtered(negative speed values), search for nearest 2 indices that are in idx(positive speed values), subjected to idx range\n",
    "#4) Using the index in idx_filtered ,range between nearest 2 indices in idx & range between idx_filtered index & 1st nearest idx, use formula to set new value for negative speed value \n",
    "#5) If either of nearest 2 indices is not found, entire row containing the negative speed value is dropped\n",
    "#6) The formula is designed such that negative speed values will be replaced with speed values that are gradually increasing/decreasing between nearest 2 positive speed values \n",
    "def negative_features(input_X,bookingID):\n",
    "    df = input_X[input_X.bookingID == bookingID]\n",
    "    df_filtered = input_X[(input_X.bookingID == bookingID) & (input_X.Speed < 0)]\n",
    "    idx_filtered = df_filtered.index.values.tolist()\n",
    "    idx = df.index.values.tolist()\n",
    "        \n",
    "    for i in idx_filtered:\n",
    "        increment_start = 1\n",
    "        increment_end = 1\n",
    "        start = i\n",
    "        end = i\n",
    "        while (idx[0] <= start-increment_start < idx[-1]) & (start-increment_start in idx_filtered):\n",
    "            increment_start += 1   \n",
    "        start -= increment_start     \n",
    "        if start >= idx[0]:\n",
    "            while (idx[0] < end+increment_end <= idx[-1]) & (end+increment_end in idx_filtered):\n",
    "                increment_end += 1\n",
    "            end += increment_end    \n",
    "            if end <= idx[-1]:\n",
    "                df.loc[i,'Speed'] = ((df['Speed'][end]-df['Speed'][start])/(end-start))*(i-start)+df['Speed'][start]  \n",
    "                df.loc[i,'acceleration_x'] = ((df['acceleration_x'][end]-df['acceleration_x'][start])/(end-start))*(i-start)+df['acceleration_x'][start] \n",
    "                df.loc[i,'acceleration_y'] = ((df['acceleration_y'][end]-df['acceleration_y'][start])/(end-start))*(i-start)+df['acceleration_y'][start] \n",
    "                df.loc[i,'acceleration_z'] = ((df['acceleration_z'][end]-df['acceleration_z'][start])/(end-start))*(i-start)+df['acceleration_z'][start] \n",
    "                df.loc[i,'gyro_x'] = ((df['gyro_x'][end]-df['gyro_x'][start])/(end-start))*(i-start)+df['gyro_x'][start] \n",
    "                df.loc[i,'gyro_y'] = ((df['gyro_y'][end]-df['gyro_y'][start])/(end-start))*(i-start)+df['gyro_y'][start] \n",
    "                df.loc[i,'gyro_z'] = ((df['gyro_z'][end]-df['gyro_z'][start])/(end-start))*(i-start)+df['gyro_z'][start]            \n",
    "            else:\n",
    "                df.drop([i],inplace=True)\n",
    "        else:\n",
    "            df.drop([i],inplace=True)\n",
    "    return df\n",
    "#Create a dataframe for new training set values(coontaining positive speed values only)\n",
    "#For each ride, smooth speed values & append to new dataframe\n",
    "train_X_final = pd.DataFrame(columns=['bookingID','Accuracy','Bearing','acceleration_x','acceleration_y','acceleration_z','gyro_x','gyro_y','gyro_z','second','Speed','label'])\n",
    "features = Parallel(n_jobs=-1, verbose=2)(delayed(negative_features)(train_X_new,i) for i in train_X_new.bookingID.unique()) \n",
    "for i, feat in tqdm(enumerate(features)):\n",
    "    train_X_final = train_X_final.append(feat)\n",
    "    \n",
    "del features\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PROCESSING(FOR TEST SET)\n",
    "#Apply negative_features to test set \n",
    "test_X_final = pd.DataFrame(columns=['bookingID','Accuracy','Bearing','acceleration_x','acceleration_y','acceleration_z','gyro_x','gyro_y','gyro_z','second','Speed','label'])\n",
    "features = Parallel(n_jobs=-1, verbose=2)(delayed(negative_features)(test_X_new,i) for i in test_X_new.bookingID.unique()) \n",
    "for i, feat in tqdm(enumerate(features)):\n",
    "    test_X_final = test_X_final.append(feat)\n",
    "    \n",
    "del features\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PROCESSING\n",
    "#Check first 5 rows of new training set\n",
    "train_X_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PROCESSING\n",
    "#Again, save new training set, in case kernel disconnects\n",
    "train_X_final.to_csv('train_X_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PROCESSING(FOR TEST SET)\n",
    "#Again, save new training set, in case kernel disconnects \n",
    "test_X_final.to_csv('test_X_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PROCESSING\n",
    "#Read new training set file\n",
    "train_X_final = pd.read_csv('train_X_final.csv')\n",
    "train_X_final.set_index('Unnamed: 0',inplace=True)\n",
    "train_X_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PROCESSING(FOR TEST SET)\n",
    "#Read new test set file \n",
    "test_X_final = pd.read_csv('test_X_final.csv')\n",
    "test_X_final.set_index('Unnamed: 0',inplace=True)\n",
    "test_X_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PROCESSING\n",
    "#Check minimum & maximum ride durations\n",
    "minimum = 1000\n",
    "maximum = 0\n",
    "for i in tqdm(train_X_final.bookingID.unique()):\n",
    "    if len(train_X_final[train_X_final['bookingID'] == i]) < minimum:\n",
    "        minimum = len(train_X_final[train_X_final['bookingID'] == i])\n",
    "    elif len(train_X_final[train_X_final['bookingID'] == i]) > maximum:\n",
    "        maximum = len(train_X_final[train_X_final['bookingID'] == i])\n",
    "minimum,maximum        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PROCESSING\n",
    "#Find rides lasting less than 15 seconds & add their bookingID to to_drop\n",
    "#Of course, feel free to play with different thresholds\n",
    "#Due to time constraint, I decided to stick with 15 seconds\n",
    "to_drop = []\n",
    "for i in tqdm(train_X_final.bookingID.unique()):\n",
    "    if len(train_X_final[train_X_final.bookingID == i]) < 15:\n",
    "        to_drop.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PROCESSING\n",
    "#Drop rides less than 15 seconds, whose bookingIDs are in to_drop\n",
    "train_X_final = train_X_final[~train_X_final['bookingID'].isin(to_drop)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PROCESSING(FOR TEST SET) \n",
    "#Find rides lasting less than 15 seconds & add their bookingID to to_drop \n",
    "to_drop = []\n",
    "for i in tqdm(test_X_final.bookingID.unique()):\n",
    "    if len(test_X_final[test_X_final.bookingID == i]) < 15:\n",
    "        to_drop.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PROCESSING(FOR TEST SET)\n",
    "#Drop rides less than 15 seconds, whose bookingIDs are in to_drop \n",
    "test_X_final = test_X_final[~test_X_final['bookingID'].isin(to_drop)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PROCESSING\n",
    "#Similarly for label set, drop rides that are not in new training set\n",
    "train_y = train_y[train_y.bookingID.isin(train_X_final.bookingID.unique())]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PROCESSING\n",
    "#Final look at number of rides remaining in training set\n",
    "train_X_final.bookingID.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PROCESSING(FOR TEST SET)\n",
    "#Final look at number of rides remaining in test set \n",
    "test_X_final.bookingID.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PROCESSING\n",
    "#Sanity check to ensure number of unique rides in both label set & training set are the same\n",
    "assert len(train_y) == train_X_final.bookingID.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE ENGINEERING\n",
    "#Create a function to calculate rate of change for creating rate-related features\n",
    "def calc_change_rate(x):\n",
    "    change = (np.diff(x) / x[:-1])\n",
    "    #change = change[np.nonzero(change)[0]]\n",
    "    change = change[~np.isnan(change)]\n",
    "    change = change[change != -np.inf]\n",
    "    change = change[change != np.inf]\n",
    "    return change.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE ENGINEERING\n",
    "#seg is the data segment for each unique ride\n",
    "#seg_id is the bookingID for each unique ride\n",
    "#For each segment, calculate summary stats & store it in X\n",
    "def create_features(seg_id,seg,X):\n",
    "    xs = pd.Series(seg['Speed'].values)    \n",
    "    X.loc[seg_id, 'mean_Speed'] = np.mean(xs)\n",
    "    rolling_speed_2_std = xs.rolling(2).std()\n",
    "    X.loc[seg_id, 'rolling_speed_2_std'] = rolling_speed_2_std.mean()\n",
    "    speed_diff = np.diff(xs)\n",
    "    X.loc[seg_id, 'hard_braking_speed_min'] = speed_diff[speed_diff < 0].min() if len(speed_diff[speed_diff < 0]) > 0 else 0\n",
    "    X.loc[seg_id, 'hard_braking_speed_std'] = speed_diff[speed_diff < 0].std() if len(speed_diff[speed_diff < 0]) > 0 else 0\n",
    "    X.loc[seg_id, 'hard_braking_speed_ptp'] = np.ptp(speed_diff[speed_diff < 0]) if len(speed_diff[speed_diff < 0]) > 0 else 0\n",
    "    X.loc[seg_id, 'hard_braking_speed_num_peaks_10'] = feature_calculators.number_peaks(speed_diff[speed_diff < 0],10) if len(speed_diff[speed_diff < 0]) > 0 else 0\n",
    "    X.loc[seg_id, 'hard_braking_speed_be_5'] = feature_calculators.binned_entropy(speed_diff[speed_diff < 0],5) if len(speed_diff[speed_diff < 0]) > 0 else 0\n",
    "    \n",
    "    X.loc[seg_id, 'hard_acc_speed_max'] = speed_diff[speed_diff > 0].max() if len(speed_diff[speed_diff > 0]) > 0 else 0\n",
    "    X.loc[seg_id, 'hard_acc_speed_std'] = speed_diff[speed_diff > 0].std() if len(speed_diff[speed_diff > 0]) > 0 else 0\n",
    "    X.loc[seg_id, 'hard_acc_speed_ptp'] = np.ptp(speed_diff[speed_diff > 0]) if len(speed_diff[speed_diff > 0]) > 0 else 0\n",
    "    X.loc[seg_id, 'hard_acc_speed_num_peaks_10'] = feature_calculators.number_peaks(speed_diff[speed_diff > 0],10) if len(speed_diff[speed_diff > 0]) > 0 else 0\n",
    "    X.loc[seg_id, 'hard_acc_speed_be_5'] = feature_calculators.binned_entropy(speed_diff[speed_diff < 0],5) if len(speed_diff[speed_diff < 0]) > 0 else 0\n",
    "    rolling_pos_speed_2_std = xs[xs>0].rolling(2).std()\n",
    "    X.loc[seg_id, 'rolling_pos_speed_2_std'] = rolling_pos_speed_2_std.mean()\n",
    "    \n",
    "    xz = pd.Series(seg['acceleration_z'].values)\n",
    "    rolling_acc_z_2_diff = xz.rolling(2).apply(lambda x:np.diff(x))\n",
    "    X.loc[seg_id, 'rolling_acc_z_diff_mean'] = rolling_acc_z_2_diff.mean()\n",
    "    X.loc[seg_id, 'max_acc_z'] = xz.max()\n",
    "    X.loc[seg_id, 'min_acc_z'] = xz.min()\n",
    "    X.loc[seg_id, 'med_acc_z'] = np.median(xz)\n",
    "    X.loc[seg_id, 'p90_acc_z'] = np.percentile(xz,90)\n",
    "    X.loc[seg_id, 'mean_acc_z_pos'] = xz[xz>0].mean()\n",
    "    X.loc[seg_id, 'mean_acc_z_neg'] = xz[xz<0].mean()\n",
    "    X.loc[seg_id, 'num_peaks_pos_acc_z_10'] = feature_calculators.number_peaks(xz[xz > 0],10) if len(xz[xz > 0]) > 0 else 0\n",
    "    X.loc[seg_id, 'num_peaks_neg_acc_z_10'] = feature_calculators.number_peaks(xz[xz < 0],10) if len(xz[xz < 0]) > 0 else 0\n",
    "    \n",
    "    xy = pd.Series(seg['acceleration_y'].values)\n",
    "    rolling_acc_y_2_diff = xy.rolling(2).apply(lambda x:np.diff(x))\n",
    "    X.loc[seg_id, 'rolling_acc_y_diff_mean'] = rolling_acc_y_2_diff.mean()\n",
    "    X.loc[seg_id, 'max_acc_y'] = xy.max()\n",
    "    X.loc[seg_id, 'min_acc_y'] = xy.min()\n",
    "    X.loc[seg_id, 'med_acc_y'] = np.median(xy)\n",
    "    X.loc[seg_id, 'p90_acc_y'] = np.percentile(xy,90)\n",
    "    X.loc[seg_id, 'mean_acc_y_pos'] = xy[xy>0].mean()\n",
    "    X.loc[seg_id, 'mean_acc_y_neg'] = xy[xy<0].mean()\n",
    "    X.loc[seg_id, 'num_peaks_pos_acc_y_10'] = feature_calculators.number_peaks(xy[xy > 0],10) if len(xy[xy > 0]) > 0 else 0\n",
    "    X.loc[seg_id, 'num_peaks_neg_acc_y_10'] = feature_calculators.number_peaks(xy[xy < 0],10) if len(xy[xy < 0]) > 0 else 0\n",
    "    \n",
    "    xx = pd.Series(seg['acceleration_x'].values)\n",
    "    rolling_acc_x_2_diff = xx.rolling(2).apply(lambda x:np.diff(x))\n",
    "    X.loc[seg_id, 'rolling_acc_x_diff_mean'] = rolling_acc_x_2_diff.mean()\n",
    "    X.loc[seg_id, 'max_acc_x'] = xx.max()\n",
    "    X.loc[seg_id, 'min_acc_x'] = xx.min()\n",
    "    X.loc[seg_id, 'med_acc_x'] = np.median(xx)\n",
    "    X.loc[seg_id, 'p90_acc_x'] = np.percentile(xx,90)\n",
    "    X.loc[seg_id, 'mean_acc_x_pos'] = xx[xx>0].mean()\n",
    "    X.loc[seg_id, 'mean_acc_x_neg'] = xx[xx<0].mean()\n",
    "    X.loc[seg_id, 'num_peaks_pos_acc_x_10'] = feature_calculators.number_peaks(xx[xx > 0],10) if len(xx[xx > 0]) > 0 else 0\n",
    "    X.loc[seg_id, 'num_peaks_neg_acc_x_10'] = feature_calculators.number_peaks(xx[xx < 0],10) if len(xx[xx < 0]) > 0 else 0\n",
    "    \n",
    "    X.loc[seg_id, 'trip_time'] = len(seg)\n",
    "     \n",
    "    ##hardbrake combos\n",
    "    temp = seg[(seg['gyro_x'] > 0) &(seg['acceleration_y'] < 0)] \n",
    "    gx_temp = pd.Series(temp['gyro_x'].values)\n",
    "    ay_temp = pd.Series(temp['acceleration_y'].values)                                 \n",
    "    s_temp = pd.Series(temp['Speed'].values)\n",
    "    X.loc[seg_id, 'gx_ay_hardbrake_min'] = np.multiply(gx_temp,ay_temp).min()\n",
    "    X.loc[seg_id, 'gx_ay_hardbrake_std'] = np.multiply(gx_temp,ay_temp).std()\n",
    "    X.loc[seg_id, 'gx_ay_hardbrake_mean'] = np.multiply(gx_temp,ay_temp).mean()\n",
    "    X.loc[seg_id, 'gx_ay_hardbrake_diff_mean'] = np.diff(np.multiply(gx_temp,ay_temp)).mean()\n",
    "    \n",
    "    X.loc[seg_id, 'gx_s_hardbrake_max'] = np.multiply(gx_temp,s_temp).max()\n",
    "    X.loc[seg_id, 'gx_s_hardbrake_std'] = np.multiply(gx_temp,s_temp).std()\n",
    "    X.loc[seg_id, 'gx_s_hardbrake_mean'] = np.multiply(gx_temp,s_temp).mean()\n",
    "    #to be del\n",
    "    X.loc[seg_id, 'gx_s_hardbrake_diff_mean'] = np.diff(np.multiply(gx_temp,s_temp)).mean()\n",
    "    \n",
    "    X.loc[seg_id, 'ay_s_hardbrake_min'] = np.multiply(ay_temp,s_temp).min()\n",
    "    X.loc[seg_id, 'ay_s_hardbrake_std'] = np.multiply(ay_temp,s_temp).std()\n",
    "    X.loc[seg_id, 'ay_s_hardbrake_mean'] = np.multiply(ay_temp,s_temp).mean()\n",
    "    X.loc[seg_id, 'ay_s_hardbrake_diff_mean'] = np.diff(np.multiply(ay_temp,s_temp)).mean()\n",
    "    \n",
    "    X.loc[seg_id, 'gx_hardbrake_max'] = gx_temp.max()\n",
    "    X.loc[seg_id, 'gx_hardbrake_mean'] = gx_temp.mean()\n",
    "    X.loc[seg_id, 'gx_hardbrake_med'] = np.median(gx_temp)\n",
    "    X.loc[seg_id, 'gx_hardbrake_std'] = gx_temp.std()\n",
    "    X.loc[seg_id, 'gx_hardbrake_90p'] = np.percentile(gx_temp,90) if len(temp) > 0 else 0\n",
    "    X.loc[seg_id, 'gx_hardbrake_diff_mean'] = np.diff(gx_temp).mean()\n",
    "    \n",
    "    X.loc[seg_id, 'ay_hardbrake_min'] = ay_temp.min()\n",
    "    X.loc[seg_id, 'ay_hardbrake_mean'] = ay_temp.mean()\n",
    "    X.loc[seg_id, 'ay_hardbrake_med'] = np.median(ay_temp)\n",
    "    #X.loc[seg_id, 'ay_hardbrake_std'] = ay_temp.std()\n",
    "    X.loc[seg_id, 'ay_hardbrake_10p'] = np.percentile(ay_temp,10) if len(temp) > 0 else 0\n",
    "    X.loc[seg_id, 'ay_hardbrake_diff_mean'] = np.diff(ay_temp).mean()\n",
    "    \n",
    "    X.loc[seg_id, 's_hardbrake_min'] = s_temp.min()\n",
    "    X.loc[seg_id, 's_hardbrake_mean'] = s_temp.mean()\n",
    "    X.loc[seg_id, 's_hardbrake_med'] = np.median(s_temp)\n",
    "    X.loc[seg_id, 's_hardbrake_std'] = s_temp.std()\n",
    "    #X.loc[seg_id, 's_hardbrake_10p'] = np.percentile(s_temp,10) if len(temp) > 0 else 0\n",
    "    #X.loc[seg_id, 's_hardbrake_diff_mean'] = np.diff(s_temp).mean()\n",
    "    ##hardbrake combos\n",
    "    \n",
    "    ##hardacc combos\n",
    "    temp = seg[(seg['gyro_x'] > 0) &(seg['acceleration_y'] > 0)] \n",
    "    gx_temp = pd.Series(temp['gyro_x'].values)\n",
    "    ay_temp = pd.Series(temp['acceleration_y'].values)\n",
    "    s_temp = pd.Series(temp['Speed'].values)\n",
    "    X.loc[seg_id, 'gx_ay_hardacc_max'] = np.multiply(gx_temp,ay_temp).max()\n",
    "    X.loc[seg_id, 'gx_ay_hardacc_std'] = np.multiply(gx_temp,ay_temp).std()\n",
    "    X.loc[seg_id, 'gx_ay_hardacc_mean'] = np.multiply(gx_temp,ay_temp).mean()\n",
    "    X.loc[seg_id, 'gx_ay_hardacc_diff_mean'] = np.diff(np.multiply(gx_temp,ay_temp)).mean()\n",
    "    \n",
    "    X.loc[seg_id, 'gx_s_hardacc_max'] = np.multiply(gx_temp,s_temp).max()\n",
    "    X.loc[seg_id, 'gx_s_hardacc_std'] = np.multiply(gx_temp,s_temp).std()\n",
    "    X.loc[seg_id, 'gx_s_hardacc_mean'] = np.multiply(gx_temp,s_temp).mean()\n",
    "    X.loc[seg_id, 'gx_s_hardacc_diff_mean'] = np.diff(np.multiply(gx_temp,s_temp)).mean()\n",
    "    \n",
    "    X.loc[seg_id, 'ay_s_hardacc_max'] = np.multiply(ay_temp,s_temp).max()\n",
    "    X.loc[seg_id, 'ay_s_hardacc_std'] = np.multiply(ay_temp,s_temp).std()\n",
    "    X.loc[seg_id, 'ay_s_hardacc_mean'] = np.multiply(ay_temp,s_temp).mean()\n",
    "    X.loc[seg_id, 'ay_s_hardacc_diff_mean'] = np.diff(np.multiply(ay_temp,s_temp)).mean()\n",
    "    \n",
    "    X.loc[seg_id, 'gx_hardacc_max'] = gx_temp.max()\n",
    "    X.loc[seg_id, 'gx_hardacc_mean'] = gx_temp.mean()\n",
    "    X.loc[seg_id, 'gx_hardacc_med'] = np.median(gx_temp)\n",
    "    X.loc[seg_id, 'gx_hardacc_std'] = gx_temp.std()\n",
    "    X.loc[seg_id, 'gx_hardacc_90p'] = np.percentile(gx_temp,90) if len(temp) > 1 else 0\n",
    "    X.loc[seg_id, 'gx_hardacc_diff_mean'] = np.diff(gx_temp).mean()\n",
    "    \n",
    "    X.loc[seg_id, 'ay_hardacc_max'] = ay_temp.max()\n",
    "    X.loc[seg_id, 'ay_hardacc_mean'] = ay_temp.mean()\n",
    "    X.loc[seg_id, 'ay_hardacc_med'] = np.median(ay_temp)\n",
    "    X.loc[seg_id, 'ay_hardacc_std'] = ay_temp.std()\n",
    "    X.loc[seg_id, 'ay_hardacc_90p'] = np.percentile(ay_temp,90) if len(temp) > 1 else 0\n",
    "    X.loc[seg_id, 'ay_hardacc_diff_mean'] = np.diff(ay_temp).mean()\n",
    "    \n",
    "    X.loc[seg_id, 's_hardacc_max'] = s_temp.max()\n",
    "    X.loc[seg_id, 's_hardacc_mean'] = s_temp.mean()\n",
    "    X.loc[seg_id, 's_hardacc_med'] = np.median(s_temp)\n",
    "    X.loc[seg_id, 's_hardacc_std'] = s_temp.std()\n",
    "    X.loc[seg_id, 's_hardacc_90p'] = np.percentile(s_temp,90) if len(temp) > 1 else 0\n",
    "    X.loc[seg_id, 's_hardacc_diff_mean'] = np.diff(s_temp).mean()\n",
    "    ##hardacc combos\n",
    "    \n",
    "    ##hardright combos\n",
    "    temp = seg[(seg['gyro_z'] < 0) &(seg['acceleration_x'] > 0)]\n",
    "    ax_temp = pd.Series(temp['acceleration_x'].values)\n",
    "    gz_temp = pd.Series(temp['gyro_z'].values)\n",
    "    s_temp = pd.Series(temp['Speed'].values)\n",
    "    X.loc[seg_id, 'ax_gz_hardright_min'] = np.multiply(ax_temp,gz_temp).min()\n",
    "    X.loc[seg_id, 'ax_gz_hardright_std'] = np.multiply(ax_temp,gz_temp).std()\n",
    "    X.loc[seg_id, 'ax_gz_hardright_mean'] = np.multiply(ax_temp,gz_temp).mean()\n",
    "    X.loc[seg_id, 'ax_gz_hardright_diff_mean'] = np.diff(np.multiply(ax_temp,gz_temp)).mean()\n",
    "    \n",
    "    X.loc[seg_id, 's_gz_hardright_min'] = np.multiply(s_temp,gz_temp).min()\n",
    "    X.loc[seg_id, 's_gz_hardright_std'] = np.multiply(s_temp,gz_temp).std()\n",
    "    X.loc[seg_id, 's_gz_hardright_mean'] = np.multiply(s_temp,gz_temp).mean()\n",
    "    X.loc[seg_id, 's_gz_hardright_diff_mean'] = np.diff(np.multiply(s_temp,gz_temp)).mean()\n",
    "    \n",
    "    X.loc[seg_id, 'ax_s_hardright_max'] = np.multiply(ax_temp,s_temp).max()\n",
    "    X.loc[seg_id, 'ax_s_hardright_std'] = np.multiply(ax_temp,s_temp).std()\n",
    "    X.loc[seg_id, 'ax_s_hardright_mean'] = np.multiply(ax_temp,s_temp).mean()\n",
    "    X.loc[seg_id, 'ax_s_hardright_diff_mean'] = np.diff(np.multiply(ax_temp,s_temp)).mean()\n",
    "    \n",
    "    X.loc[seg_id, 'gz_hardright_min'] = gz_temp.min()\n",
    "    X.loc[seg_id, 'gz_hardright_mean'] = gz_temp.mean()\n",
    "    X.loc[seg_id, 'gz_hardright_med'] = np.median(gz_temp)\n",
    "    X.loc[seg_id, 'gz_hardright_std'] = gz_temp.std()\n",
    "    X.loc[seg_id, 'gz_hardright_10p'] = np.percentile(gz_temp,10) if len(temp) > 0 else 0\n",
    "    X.loc[seg_id, 'gz_hardright_diff_mean'] = np.diff(gz_temp).mean()\n",
    "    \n",
    "    X.loc[seg_id, 'ax_hardright_max'] = ax_temp.max()\n",
    "    X.loc[seg_id, 'ax_hardright_mean'] = ax_temp.mean()\n",
    "    X.loc[seg_id, 'ax_hardright_med'] = np.median(ax_temp)\n",
    "    X.loc[seg_id, 'ax_hardright_std'] = ax_temp.std()\n",
    "    X.loc[seg_id, 'ax_hardright_90p'] = np.percentile(ax_temp,90) if len(temp) > 0 else 0\n",
    "    X.loc[seg_id, 'ax_hardright_diff_mean'] = np.diff(ax_temp).mean()\n",
    "    \n",
    "    X.loc[seg_id, 's_hardright_max'] = s_temp.max()\n",
    "    X.loc[seg_id, 's_hardright_mean'] = s_temp.mean()\n",
    "    X.loc[seg_id, 's_hardright_med'] = np.median(s_temp)\n",
    "    X.loc[seg_id, 's_hardright_std'] = s_temp.std()\n",
    "    X.loc[seg_id, 's_hardright_90p'] = np.percentile(s_temp,90) if len(temp) > 0 else 0\n",
    "    X.loc[seg_id, 's_hardright_diff_mean'] = np.diff(s_temp).mean()\n",
    "    ##hardright combos\n",
    "    \n",
    "    ##hardleft combos\n",
    "    temp = seg[(seg['gyro_z'] > 0) &(seg['acceleration_x'] < 0)]\n",
    "    ax_temp = pd.Series(temp['acceleration_x'].values)\n",
    "    gz_temp = pd.Series(temp['gyro_z'].values)\n",
    "    s_temp = pd.Series(temp['Speed'].values)\n",
    "    X.loc[seg_id, 'ax_gz_hardleft_min'] = np.multiply(ax_temp,gz_temp).min()\n",
    "    X.loc[seg_id, 'ax_gz_hardleft_std'] = np.multiply(ax_temp,gz_temp).std()\n",
    "    X.loc[seg_id, 'ax_gz_hardleft_mean'] = np.multiply(ax_temp,gz_temp).mean()\n",
    "    X.loc[seg_id, 'ax_gz_hardleft_diff_mean'] = np.diff(np.multiply(ax_temp,gz_temp)).mean()\n",
    "    \n",
    "    X.loc[seg_id, 's_gz_hardleft_max'] = np.multiply(s_temp,gz_temp).max()\n",
    "    X.loc[seg_id, 's_gz_hardleft_std'] = np.multiply(s_temp,gz_temp).std()\n",
    "    X.loc[seg_id, 's_gz_hardleft_mean'] = np.multiply(s_temp,gz_temp).mean()\n",
    "    X.loc[seg_id, 's_gz_hardleft_diff_mean'] = np.diff(np.multiply(s_temp,gz_temp)).mean()\n",
    "    \n",
    "    X.loc[seg_id, 'ax_s_hardleft_min'] = np.multiply(ax_temp,s_temp).min()\n",
    "    X.loc[seg_id, 'ax_s_hardleft_std'] = np.multiply(ax_temp,s_temp).std()\n",
    "    X.loc[seg_id, 'ax_s_hardleft_mean'] = np.multiply(ax_temp,s_temp).mean()\n",
    "    X.loc[seg_id, 'ax_s_hardleft_diff_mean'] = np.diff(np.multiply(ax_temp,s_temp)).mean()\n",
    "    \n",
    "    X.loc[seg_id, 'gz_hardleft_max'] = gz_temp.max()\n",
    "    X.loc[seg_id, 'gz_hardleft_mean'] = gz_temp.mean()\n",
    "    X.loc[seg_id, 'gz_hardleft_med'] = np.median(gz_temp)\n",
    "    X.loc[seg_id, 'gz_hardleft_std'] = gz_temp.std()\n",
    "    X.loc[seg_id, 'gz_hardleft_90p'] = np.percentile(gz_temp,90) if len(temp) > 0 else 0\n",
    "    X.loc[seg_id, 'gz_hardleft_diff_mean'] = np.diff(gz_temp).mean()\n",
    "    \n",
    "    X.loc[seg_id, 'ax_hardleft_min'] = ax_temp.min()\n",
    "    X.loc[seg_id, 'ax_hardleft_mean'] = ax_temp.mean()\n",
    "    X.loc[seg_id, 'ax_hardleft_med'] = np.median(ax_temp)\n",
    "    X.loc[seg_id, 'ax_hardleft_std'] = ax_temp.std()\n",
    "    X.loc[seg_id, 'ax_hardleft_10p'] = np.percentile(ax_temp,10) if len(temp) > 0 else 0\n",
    "    X.loc[seg_id, 'ax_hardleft_diff_mean'] = np.diff(ax_temp).mean()\n",
    "    \n",
    "    X.loc[seg_id, 's_hardleft_max'] = s_temp.max()\n",
    "    X.loc[seg_id, 's_hardleft_mean'] = s_temp.mean()\n",
    "    X.loc[seg_id, 's_hardleft_med'] = np.median(s_temp)\n",
    "    X.loc[seg_id, 's_hardleft_std'] = s_temp.std()\n",
    "    X.loc[seg_id, 's_hardleft_90p'] = np.percentile(s_temp,90) if len(temp) > 0 else 0\n",
    "    X.loc[seg_id, 's_hardleft_diff_mean'] = np.diff(s_temp).mean()\n",
    "    ##hardleft combos\n",
    "    \n",
    "    ##hardswerveright combos\n",
    "    temp = seg[(seg['gyro_y'] > 0) &(seg['acceleration_x'] > 0)] \n",
    "    ax_temp = pd.Series(temp['acceleration_x'].values)\n",
    "    gy_temp = pd.Series(temp['gyro_y'].values)\n",
    "    s_temp = pd.Series(temp['Speed'].values)\n",
    "    X.loc[seg_id, 'gy_ax_hardSright_max'] = np.multiply(gy_temp,ax_temp).max()\n",
    "    X.loc[seg_id, 'gy_ax_hardSright_std'] = np.multiply(gy_temp,ax_temp).std()\n",
    "    X.loc[seg_id, 'gy_ax_hardSright_mean'] = np.multiply(gy_temp,ax_temp).mean()\n",
    "    X.loc[seg_id, 'gy_ax_hardSright_diff_mean'] = np.diff(np.multiply(gy_temp,ax_temp)).mean()\n",
    "    \n",
    "    X.loc[seg_id, 'gy_s_hardSright_max'] = np.multiply(gy_temp,s_temp).max()\n",
    "    X.loc[seg_id, 'gy_s_hardSright_std'] = np.multiply(gy_temp,s_temp).std()\n",
    "    X.loc[seg_id, 'gy_s_hardSright_mean'] = np.multiply(gy_temp,s_temp).mean()\n",
    "    X.loc[seg_id, 'gy_s_hardSright_diff_mean'] = np.diff(np.multiply(gy_temp,s_temp)).mean()\n",
    "    \n",
    "    X.loc[seg_id, 'ax_s_hardSright_max'] = np.multiply(ax_temp,s_temp).max()\n",
    "    X.loc[seg_id, 'ax_s_hardSright_std'] = np.multiply(ax_temp,s_temp).std()\n",
    "    X.loc[seg_id, 'ax_s_hardSright_mean'] = np.multiply(ax_temp,s_temp).mean()\n",
    "    X.loc[seg_id, 'ax_s_hardSright_diff_mean'] = np.diff(np.multiply(ax_temp,s_temp)).mean()\n",
    "    \n",
    "    X.loc[seg_id, 'gy_hardSright_max'] = gy_temp.max()\n",
    "    X.loc[seg_id, 'gy_hardSright_mean'] = gy_temp.mean()\n",
    "    X.loc[seg_id, 'gy_hardSright_med'] = np.median(gy_temp)\n",
    "    X.loc[seg_id, 'gy_hardSright_std'] = gy_temp.std()\n",
    "    X.loc[seg_id, 'gy_hardSright_90p'] = np.percentile(gy_temp,90) if len(temp) > 0 else 0\n",
    "    X.loc[seg_id, 'gy_hardSright_diff_mean'] = np.diff(gy_temp).mean()\n",
    "    \n",
    "    X.loc[seg_id, 'ax_hardSright_max'] = ax_temp.max()\n",
    "    X.loc[seg_id, 'ax_hardSright_mean'] = ax_temp.mean()\n",
    "    X.loc[seg_id, 'ax_hardSright_med'] = np.median(ax_temp)\n",
    "    X.loc[seg_id, 'ax_hardSright_std'] = ax_temp.std()\n",
    "    X.loc[seg_id, 'ax_hardSright_90p'] = np.percentile(ax_temp,90) if len(temp) > 0 else 0\n",
    "    X.loc[seg_id, 'ax_hardSright_diff_mean'] = np.diff(ax_temp).mean()\n",
    "    \n",
    "    X.loc[seg_id, 's_hardSright_max'] = s_temp.max()\n",
    "    X.loc[seg_id, 's_hardSright_mean'] = s_temp.mean()\n",
    "    X.loc[seg_id, 's_hardSright_med'] = np.median(s_temp)\n",
    "    X.loc[seg_id, 's_hardSright_std'] = s_temp.std()\n",
    "    X.loc[seg_id, 's_hardSright_90p'] = np.percentile(s_temp,90) if len(temp) > 0 else 0\n",
    "    X.loc[seg_id, 's_hardSright_diff_mean'] = np.diff(s_temp).mean()\n",
    "    ##hardswerveright combos\n",
    "    \n",
    "    ##hardswerveleft combos\n",
    "    temp = seg[(seg['gyro_y'] < 0) &(seg['acceleration_x'] < 0)] \n",
    "    ax_temp = pd.Series(temp['acceleration_x'].values)\n",
    "    gy_temp = pd.Series(temp['gyro_y'].values)\n",
    "    s_temp = pd.Series(temp['Speed'].values)\n",
    "    X.loc[seg_id, 'gy_ax_hardSleft_max'] = np.multiply(gy_temp,ax_temp).max()\n",
    "    X.loc[seg_id, 'gy_ax_hardSleft_std'] = np.multiply(gy_temp,ax_temp).std()\n",
    "    X.loc[seg_id, 'gy_ax_hardSleft_mean'] = np.multiply(gy_temp,ax_temp).mean()\n",
    "    X.loc[seg_id, 'gy_ax_hardSleft_diff_mean'] = np.diff(np.multiply(gy_temp,ax_temp)).mean()\n",
    "    \n",
    "    X.loc[seg_id, 'ax_s_hardSleft_min'] = np.multiply(ax_temp,s_temp).min()\n",
    "    X.loc[seg_id, 'ax_s_hardSleft_std'] = np.multiply(ax_temp,s_temp).std()\n",
    "    X.loc[seg_id, 'ax_s_hardSleft_mean'] = np.multiply(ax_temp,s_temp).mean()\n",
    "    X.loc[seg_id, 'ax_s_hardSleft_diff_mean'] = np.diff(np.multiply(ax_temp,s_temp)).mean()\n",
    "    \n",
    "    X.loc[seg_id, 'gy_s_hardSleft_min'] = np.multiply(gy_temp,s_temp).min()\n",
    "    X.loc[seg_id, 'gy_s_hardSleft_std'] = np.multiply(gy_temp,s_temp).std()\n",
    "    X.loc[seg_id, 'gy_s_hardSleft_mean'] = np.multiply(gy_temp,s_temp).mean()\n",
    "    X.loc[seg_id, 'gy_s_hardSleft_diff_mean'] = np.diff(np.multiply(gy_temp,s_temp)).mean()\n",
    "    \n",
    "    X.loc[seg_id, 'gy_hardSleft_min'] = gy_temp.min()\n",
    "    X.loc[seg_id, 'gy_hardSleft_mean'] = gy_temp.mean()\n",
    "    X.loc[seg_id, 'gy_hardSleft_med'] = np.median(gy_temp)\n",
    "    X.loc[seg_id, 'gy_hardSleft_std'] = gy_temp.std()\n",
    "    X.loc[seg_id, 'gy_hardSleft_10p'] = np.percentile(gy_temp,10) if len(temp) > 0 else 0\n",
    "    X.loc[seg_id, 'gy_hardSleft_diff_mean'] = np.diff(gy_temp).mean()\n",
    "    \n",
    "    X.loc[seg_id, 'ax_hardSleft_min'] = ax_temp.min()\n",
    "    X.loc[seg_id, 'ax_hardSleft_mean'] = ax_temp.mean()\n",
    "    X.loc[seg_id, 'ax_hardSleft_med'] = np.median(ax_temp)\n",
    "    X.loc[seg_id, 'ax_hardSleft_std'] = ax_temp.std()\n",
    "    X.loc[seg_id, 'ax_hardSleft_10p'] = np.percentile(ax_temp,10) if len(temp) > 0 else 0\n",
    "    X.loc[seg_id, 'ax_hardSleft_diff_mean'] = np.diff(ax_temp).mean()\n",
    "    \n",
    "    X.loc[seg_id, 's_hardSleft_max'] = s_temp.max()\n",
    "    X.loc[seg_id, 's_hardSleft_mean'] = s_temp.mean()\n",
    "    X.loc[seg_id, 's_hardSleft_med'] = np.median(s_temp)\n",
    "    X.loc[seg_id, 's_hardSleft_std'] = s_temp.std()\n",
    "    X.loc[seg_id, 's_hardSleft_90p'] = np.percentile(s_temp,90) if len(temp) > 0 else 0\n",
    "    X.loc[seg_id, 's_hardSleft_diff_mean'] = np.diff(s_temp).mean()\n",
    "    ##hardswerveleft combos\n",
    "    \n",
    "    ##hardbump combos\n",
    "    temp = seg[(seg['gyro_x'] > 0) &(seg['acceleration_z'] > 0)] \n",
    "    az_temp = pd.Series(temp['acceleration_z'].values)\n",
    "    gx_temp = pd.Series(temp['gyro_x'].values)\n",
    "    s_temp = pd.Series(temp['Speed'].values)\n",
    "    X.loc[seg_id, 'az_s_hardbump_max'] = np.multiply(az_temp,s_temp).max()\n",
    "    X.loc[seg_id, 'az_s_hardbump_std'] = np.multiply(az_temp,s_temp).std()\n",
    "    X.loc[seg_id, 'az_s_hardbump_mean'] = np.multiply(az_temp,s_temp).mean()\n",
    "    X.loc[seg_id, 'az_s_hardbump_diff_mean'] = np.diff(np.multiply(az_temp,s_temp)).mean()\n",
    "    \n",
    "    X.loc[seg_id, 'az_gx_hardbump_max'] = np.multiply(az_temp,gx_temp).max()\n",
    "    X.loc[seg_id, 'az_gx_hardbump_std'] = np.multiply(az_temp,gx_temp).std()\n",
    "    X.loc[seg_id, 'az_gx_hardbump_mean'] = np.multiply(az_temp,gx_temp).mean()\n",
    "    X.loc[seg_id, 'az_gx_hardbump_diff_mean'] = np.diff(np.multiply(az_temp,gx_temp)).mean()\n",
    "    \n",
    "    X.loc[seg_id, 's_gx_hardbump_max'] = np.multiply(s_temp,gx_temp).max()\n",
    "    X.loc[seg_id, 's_gx_hardbump_std'] = np.multiply(s_temp,gx_temp).std()\n",
    "    X.loc[seg_id, 's_gx_hardbump_mean'] = np.multiply(s_temp,gx_temp).mean()\n",
    "    X.loc[seg_id, 's_gx_hardbump_diff_mean'] = np.diff(np.multiply(s_temp,gx_temp)).mean()\n",
    "    \n",
    "    X.loc[seg_id, 'gx_hardbump_max'] = gx_temp.max()\n",
    "    X.loc[seg_id, 'gx_hardbump_mean'] = gx_temp.mean()\n",
    "    X.loc[seg_id, 'gx_hardbump_med'] = np.median(gx_temp)\n",
    "    X.loc[seg_id, 'gx_hardbump_std'] = gx_temp.std()\n",
    "    X.loc[seg_id, 'gx_hardbump_90p'] = np.percentile(gx_temp,90) if len(temp) > 0 else 0\n",
    "    X.loc[seg_id, 'gx_hardbump_diff_mean'] = np.diff(gx_temp).mean()\n",
    "    \n",
    "    X.loc[seg_id, 'az_hardbump_max'] = az_temp.max()\n",
    "    X.loc[seg_id, 'az_hardbump_mean'] = az_temp.mean()\n",
    "    X.loc[seg_id, 'az_hardbump_med'] = np.median(az_temp)\n",
    "    X.loc[seg_id, 'az_hardbump_std'] = az_temp.std()\n",
    "    X.loc[seg_id, 'az_hardbump_90p'] = np.percentile(az_temp,90) if len(temp) > 0 else 0\n",
    "    X.loc[seg_id, 'az_hardbump_diff_mean'] = np.diff(az_temp).mean()\n",
    "    \n",
    "    X.loc[seg_id, 's_hardbump_max'] = s_temp.max()\n",
    "    X.loc[seg_id, 's_hardbump_mean'] = s_temp.mean()\n",
    "    X.loc[seg_id, 's_hardbump_med'] = np.median(s_temp)\n",
    "    X.loc[seg_id, 's_hardbump_std'] = s_temp.std()\n",
    "    X.loc[seg_id, 's_hardbump_90p'] = np.percentile(s_temp,90) if len(temp) > 0 else 0\n",
    "    X.loc[seg_id, 's_hardbump_diff_mean'] = np.diff(s_temp).mean()\n",
    "    ##hardbump combos\n",
    "    \n",
    "    #specials\n",
    "    power = np.multiply(xs,xy)\n",
    "    X.loc[seg_id, 'power_mean'] = power.mean()\n",
    "    X.loc[seg_id, 'power_std'] = power.std()\n",
    "    X.loc[seg_id, 'power_max'] = power.max()\n",
    "    X.loc[seg_id, 'power_min'] = power.min()\n",
    "    X.loc[seg_id, 'power_med'] = np.median(power)\n",
    "    X.loc[seg_id, 'power_pos_mean'] = power[power>0].mean()\n",
    "    X.loc[seg_id, 'power_pos_max'] = power[power>0].max()\n",
    "    X.loc[seg_id, 'power_pos_std'] = power[power>0].std()\n",
    "    X.loc[seg_id, 'power_neg_mean'] = power[power<0].mean()\n",
    "    X.loc[seg_id, 'power_neg_min'] = power[power<0].min()\n",
    "    X.loc[seg_id, 'power_neg_std'] = power[power<0].std()\n",
    "\n",
    "    bb = pd.Series(seg['Bearing'].values)\n",
    "    diff = np.diff(bb)\n",
    "    turn_power = np.multiply(diff,power[:-1]).values\n",
    "    X.loc[seg_id, 'turn_power_mean'] = turn_power.mean()\n",
    "     \n",
    "    return X\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE ENGINEERING\n",
    "#Create a new training dataframe for storing newly-created features for each ride\n",
    "#Create a new label dataframe so that bookingID becomes index\n",
    "train_X_final_2 = pd.DataFrame(index=pd.Series(train_y.bookingID), dtype=np.float64)\n",
    "train_y_final = pd.DataFrame(index=pd.Series(train_y.bookingID),dtype=np.float64)\n",
    "train_y_final['label'] = train_y['label'].values\n",
    "train_X_final_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE ENGINEERING(FOR TEST SET) \n",
    "#Create another new test set for test set summary stat features \n",
    "test_X_final_2 = pd.DataFrame(index=pd.Series(test_X_final.bookingID), dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE ENGINEERING\n",
    "#Sanity check to ensure no. of unique rides are the same in train set & label set\n",
    "assert len(train_X_final_2) == len(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE ENGINEERING\n",
    "#Create features & store them to train_X_final_2\n",
    "#I didn't use parallel processing here since feature creation is quite fast(~1hour)\n",
    "for seg_id in tqdm(train_X_final.bookingID.unique()):\n",
    "    seg = train_X_final[train_X_final['bookingID'] == seg_id]\n",
    "    train_X_final_2 = create_features(seg_id, seg, train_X_final_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE ENGINEERING(FOR TEST SET)\n",
    "#Create features & store them to test_X_final_2\n",
    "#I didn't use parallel processing here since feature creation is quite fast(~1hour)\n",
    "for seg_id in tqdm(test_X_final.bookingID.unique()):\n",
    "    seg = test_X_final[test_X_final['bookingID'] == seg_id]\n",
    "    test_X_final_2 = create_features(seg_id, seg, test_X_final_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE ENGINEERING\n",
    "#Sanity check for inf values, which shouldn't exist\n",
    "for i in train_X_final_2.columns.unique():\n",
    "    if np.isinf(train_X_final_2[i]).any() == True:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE ENGINEERING(FOR TEST SET)\n",
    "#Sanity check for inf values, which shouldn't exist\n",
    "for i in test_X_final_2.columns.unique():\n",
    "    if np.isinf(test_X_final_2[i]).any() == True:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE ENGINEERING\n",
    "#Check first 5 rows of final training set\n",
    "train_X_final_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE ENGINEERING(FOR TEST SET)\n",
    "test_X_final_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE ENGINEERING\n",
    "#Check first 5 rows of train y\n",
    "train_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE ENGINEERING\n",
    "#Use StandardScaler to scale training set features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_X_final_2)\n",
    "scaled_train_X = pd.DataFrame(scaler.transform(train_X_final_2), columns=train_X_final_2.columns,index=train_X_final_2.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE ENGINEERING(FOR TEST SET)\n",
    "#Use StandardScaler to scale test set features \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(test_X_final_2)\n",
    "scaled_test_X = pd.DataFrame(scaler.transform(test_X_final_2), columns=test_X_final_2.columns,index=test_X_final_2.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE ENGINEERING\n",
    "#Assign label values to train_y_final_2 for use in Lightgbm model later\n",
    "train_y_final_2 = train_y_final['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE ENGINEERING\n",
    "#Checking no. of rows & columns for scaled_train_X, the final training set containing all the scaled features\n",
    "scaled_train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE ENGINEERING(FOR TEST SET)\n",
    "#Checking no. of rows & columns for scaled_test_X, the final test set containing all the scaled features\n",
    "scaled_test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODELING\n",
    "#Due to imbalanced class, I decided to do data augmentation within each fold by up-sampling both classes(but up-sampling more of class 1)\n",
    "def augment(input_X,input_y):\n",
    "    #Triples minor category\n",
    "    mask = input_y>0\n",
    "    x1 = input_X[mask].copy()     \n",
    "    new_input_X = input_X.append(x1.sample(frac=1))\n",
    "    new_input_X = new_input_X.append(x1.sample(frac=1))\n",
    "    new_input_y = input_y.append(input_y[mask])\n",
    "    new_input_y = new_input_y.append(input_y[mask])\n",
    "    \n",
    "    #Doubles major category\n",
    "    mask = input_y==0\n",
    "    x1 = input_X[mask].copy()\n",
    "    new_input_X = new_input_X.append(x1.sample(frac=1))\n",
    "    new_input_y = new_input_y.append(input_y[mask])\n",
    "    \n",
    "    return new_input_X,new_input_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODELING\n",
    "folds = 5\n",
    "random_state = 0\n",
    "skf = StratifiedKFold(n_splits=folds,shuffle=True,random_state=random_state)\n",
    "#kf = KFold(n_splits=folds,shuffle=True,random_state=random_state)\n",
    "predictions = np.zeros(len(scaled_test_X))\n",
    "#scores = []\n",
    "#train_columns = scaled_train_X.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODELING\n",
    "#Model paramters are as shown\n",
    "#I played around with the hyperparameters until a decent gap between train & val scores is achieved\n",
    "#Of course, feel free to further-tweak the model to improve model accuracy\n",
    "params = {\n",
    "    \"objective\" : \"binary\",\n",
    "    \"metric\" : \"auc\",\n",
    "    \"boosting\": 'gbdt',\n",
    "    \"max_depth\" : -1,\n",
    "    \"num_leaves\" :13,\n",
    "    \"num_threads\" : 8,\n",
    "    \"learning_rate\" : 0.01,\n",
    "    \"bagging_freq\": 5,\n",
    "    \"bagging_fraction\" : 0.4,\n",
    "    \"feature_fraction\" : 0.01,\n",
    "    #\"min_data_in_leaf\": 300,\n",
    "    \"min_sum_hessian_in_leaf\" : 400,\n",
    "    \"tree_learner\": \"serial\",\n",
    "    \"boost_from_average\": \"false\",\n",
    "    \"lambda_l1\" : 5,\n",
    "    #\"lambda_l2\" : 5,\n",
    "    \"bagging_seed\" : random_state,\n",
    "    \"verbosity\" : -1,\n",
    "    \"seed\": random_state\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODELING\n",
    "#I'm using Lightgbm since I'm most-comfortable with this model(after using it for kaggle competitions & achieving decent results)\n",
    "#Online sources suggested LSTM as well. Due to time constraints however, I'm not doing a blend of different models\n",
    "#Within each fold, I augment 5 times. 25 times in total\n",
    "feature_importance = pd.DataFrame()\n",
    "yp_final = 0\n",
    "for fold_, (trn_idx, val_idx) in enumerate(skf.split(scaled_train_X,train_y_final_2)):\n",
    "    \n",
    "    \n",
    "    print(\"Current Fold: {}\".format(fold_))\n",
    "    input_train = scaled_train_X.iloc[trn_idx]\n",
    "    target_train = train_y_final_2.iloc[trn_idx]\n",
    "    N = 5\n",
    "    yp = 0\n",
    "    for i in range(N):\n",
    "        auginput_train,augtarget_train = augment(input_train,target_train)\n",
    "        trn_data = lgb.Dataset(auginput_train, label=augtarget_train)\n",
    "        val_data = lgb.Dataset(scaled_train_X.iloc[val_idx], label=train_y_final_2.iloc[val_idx])\n",
    "        evals_result = {}\n",
    "        model = lgb.train(params,trn_data,100000,valid_sets = [trn_data, val_data],early_stopping_rounds=1000,verbose_eval = 1000,evals_result=evals_result)                   \n",
    "        yp += model.predict(scaled_test_X)     \n",
    "          \n",
    "    yp_final += (yp/N)\n",
    "predictions = yp_final/folds    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODELING\n",
    "#A gauge of how our model performs overall on the training set\n",
    "#Of course, this is a slightly-inaccurate gauge since there is definitely leakage between training set & 'test set'(which is also training set)\n",
    "roc_auc_score(train_y_final_2, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE IMPORTANCES\n",
    "#Use shap to plot bar-chart that shows feature importances in descending order\n",
    "#This is better than the default feature_importances_ of lightgbm since the lightgbm version uses no. of splits to judge a feature's importance\n",
    "X_importance = scaled_train_X\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_importance)\n",
    "shap.summary_plot(shap_values, X_importance, plot_type='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE IMPORTANCES\n",
    "#Can drop features based on shap values\n",
    "#However, doing this seems to produce erratic results so I shall skip this\n",
    "\n",
    "#shap_sum = np.abs(shap_values).mean(axis=0)\n",
    "#importance_df = pd.DataFrame([scaled_train_X.columns.tolist(), shap_sum.tolist()]).T\n",
    "#importance_df.columns = ['column_name', 'shap_importance']\n",
    "#importance_df = importance_df.sort_values('shap_importance', ascending=False)\n",
    "#to_remove = importance_df[importance_df['shap_importance'] < 0.001]\n",
    "#to_drop = to_remove['column_name'].tolist()\n",
    "#scaled_train_X_filtered = scaled_train_X.drop((i for i in to_drop),axis=1)\n",
    "#scaled_test_X_filtered = scaled_test_X.drop((i for i in to_drop),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SUBMISSION\n",
    "#Save predictions to csv file\n",
    "test_pred =pd.DataFrame(dtype=np.float64)\n",
    "test_pred['bookingID'] = test_X_final_2.index\n",
    "test_pred['label'] = predictions\n",
    "test_pred.to_csv('predictions.csv', index=False)\n",
    "test_pred.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
